from openai import OpenAI
import json
import threading


class AiSystem:

    def __init__(self):
        # åŸºæœ¬APIçš„é…ç½®
        api_key = 'sk-zk231afdd49ac82b15607ce790bb887264a68d1b3698612a'
        api_url = 'https://api.zhizengzeng.com/v1'
        self.model = 'gemini-2.0-flash'

        # è®°å½•å¯¹è¯å†å²
        self.messages = [{'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„AIï¼Œæ˜¯ä¸€ä¸ªå‚²å¨‡å¯çˆ±çš„å–µå¨˜'}]

        # å¯¹è¯è½®æ•°é˜ˆå€¼å’Œè®¡æ•°å™¨
        self.compression_threshold = 10  # è¶…è¿‡10æ¡æ¶ˆæ¯å°±è§¦å‘æ€»ç»“
        self.current_message_count = 0

        # ğŸŒŸ å¼‚æ­¥å‹ç¼©ç›¸å…³
        self.is_compressing = False  # æ˜¯å¦æ­£åœ¨å‹ç¼©
        self.compression_lock = threading.Lock()  # çº¿ç¨‹é”

        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        self.client = OpenAI(api_key=api_key, base_url=api_url)

    def add_message(self, role, content):
        self.messages.append({
            'role': role,
            'content': content
        })
        # æ¯æ–°å¢ä¸€æ¡æ¶ˆæ¯ï¼Œè®¡æ•°å™¨ +1
        self.current_message_count += 1

    def get_requests(self):
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.messages,
            stream=True
        )
        return response

    def ai_output(self, response):
        print('AI:', end='')
        full_content = ''
        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content is not None:
                ai_content = chunk.choices[0].delta.content
                print(ai_content, end='', flush=True)
                full_content += ai_content
        print()
        return full_content

    def _async_compress_history(self):
        """ğŸŒŸ åå°å¼‚æ­¥æ‰§è¡Œå‹ç¼©"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨å‹ç¼©
        with self.compression_lock:
            if self.is_compressing:
                return  # å¦‚æœå·²ç»åœ¨å‹ç¼©ï¼Œè·³è¿‡
            self.is_compressing = True
            print("\n--- ğŸ”„ åå°å¼€å§‹æ€»ç»“å†å²å¯¹è¯ï¼ˆä¸å½±å“ç»§ç»­èŠå¤©ï¼‰... ---")

        try:
            # 1. å¿«ç…§å½“å‰éœ€è¦æ€»ç»“çš„æ¶ˆæ¯ï¼ˆé¿å…è¢«æ–°å¯¹è¯å¹²æ‰°ï¼‰
            # è·å–æ‰€æœ‰ user/assistant æ¶ˆæ¯
            with self.compression_lock:
                all_conversations = [m for m in self.messages if m['role'] in ['user', 'assistant']]

                # å¦‚æœæ¶ˆæ¯ä¸å¤Ÿå¤šï¼Œä¸å‹ç¼©
                if len(all_conversations) <= 4:
                    self.is_compressing = False
                    return

                # ä¿ç•™æœ€å4æ¡ï¼ˆ2è½®å¯¹è¯ï¼‰ï¼Œå…¶ä½™çš„ç”¨æ¥æ€»ç»“
                messages_to_summarize = all_conversations[:-4]
                history_snapshot = messages_to_summarize.copy()

            # 2. æ„é€ æ€»ç»“ prompt
            summary_prompt = "è¯·æ ¹æ®ä»¥ä¸‹å†å²å¯¹è¯ï¼Œç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“å‡ºä¸€ä¸ª**ç²¾ç‚¼çš„ã€è¿è´¯çš„**æ‘˜è¦ï¼Œæ‘˜è¦åº”ä»¥'æˆ‘ä»¬ä¹‹å‰è¿›è¡Œäº†ä»¥ä¸‹å¯¹è¯ï¼š'å¼€å¤´ï¼Œé‡ç‚¹ä¿ç•™å¯¹è¯çš„ä¸»é¢˜ã€å…³é”®ä¿¡æ¯å’Œå°šæœªè§£å†³çš„é—®é¢˜ï¼Œä»¥ä¾¿AIåŸºäºè¿™ä¸ªæ‘˜è¦ç»§ç»­å¯¹è¯ã€‚è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–è§£é‡Šæˆ–è¯„è®ºã€‚\n\n"
            summary_prompt += json.dumps(history_snapshot, ensure_ascii=False, indent=2)

            # 3. è°ƒç”¨æ¨¡å‹è¿›è¡Œæ€»ç»“ï¼ˆè¿™éƒ¨åˆ†è€—æ—¶ï¼Œä½†ä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰
            summary_response = self.client.chat.completions.create(
                model='gemini-2.0-flash',  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹è¿›è¡Œæ€»ç»“
                messages=[
                    {"role": "user", "content": summary_prompt}
                ],
                temperature=0.0  # ç¡®ä¿æ€»ç»“å†…å®¹ç¨³å®š
            )
            summary_content = summary_response.choices[0].message.content

            # 4. å‹ç¼©å®Œæˆåï¼Œæ›¿æ¢å†å²
            with self.compression_lock:
                system_message = self.messages[0]
                # ğŸŒŸ æ”¹æˆ assistant è§’è‰²
                summary_message = {'role': 'assistant', 'content': f"[å†å²å¯¹è¯æ‘˜è¦]\n{summary_content}"}

                # è·å–æœ€æ–°çš„å¯¹è¯æ¶ˆæ¯ï¼ˆå¯èƒ½åœ¨å‹ç¼©è¿‡ç¨‹ä¸­åˆå¢åŠ äº†æ–°å¯¹è¯ï¼‰
                current_conversations = [m for m in self.messages if m['role'] in ['user', 'assistant']]
                recent_messages = current_conversations[-4:]  # ä¿ç•™æœ€å4æ¡

                # é‡å»ºæ¶ˆæ¯åˆ—è¡¨
                self.messages = [system_message, summary_message] + recent_messages

                # é‡ç½®è®¡æ•°å™¨ï¼ˆåªè®¡ç®— user/assistant æ¶ˆæ¯ï¼‰
                self.current_message_count = len(recent_messages)

                print(f"\n--- âœ… å†å²å‹ç¼©å®Œæˆï¼æ€»ç»“äº† {len(history_snapshot)} æ¡æ¶ˆæ¯ â†’ 1 æ¡æ‘˜è¦ ---")
                print(f"--- å½“å‰ä¿ç•™ï¼šç³»ç»Ÿæ¶ˆæ¯(1) + æ‘˜è¦(1) + æœ€è¿‘å¯¹è¯({len(recent_messages)}) ---\n")
                self.is_compressing = False

        except Exception as e:
            print(f"\n--- âŒ å‹ç¼©è¿‡ç¨‹ä¸­å‡ºé”™ï¼š{e} ---\n")
            with self.compression_lock:
                self.is_compressing = False

    def chat(self):
        print(self.messages)
        # 1. ç”¨æˆ·è¾“å…¥
        user = input('ä½ ï¼š')
        self.add_message('user', user)

        # 2. è·å– AI å›å¤
        response = self.get_requests()
        ai_content = self.ai_output(response)

        # 3. æ–°å¢ assistant æ¶ˆæ¯
        self.add_message('assistant', ai_content)

        # 4. ğŸŒŸ æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ï¼ˆå¼‚æ­¥è§¦å‘ï¼Œä¸é˜»å¡ï¼‰
        if self.current_message_count > self.compression_threshold and not self.is_compressing:
            # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå‹ç¼©ï¼Œä¸é˜»å¡å¯¹è¯
            compress_thread = threading.Thread(
                target=self._async_compress_history,
                daemon=True  # å®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
            )
            compress_thread.start()

        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        status = f"æ­£åœ¨å‹ç¼©ä¸­..." if self.is_compressing else ""
        print(f"(å½“å‰æ¶ˆæ¯æ•°ï¼š{self.current_message_count}) {status}")

    def main(self):
        print("=== ğŸ˜º å–µå¨˜AIèŠå¤©ç³»ç»Ÿï¼ˆæ”¯æŒå¼‚æ­¥å†å²å‹ç¼©ï¼‰===")
        print(f"æç¤ºï¼šè¶…è¿‡ {self.compression_threshold} æ¡æ¶ˆæ¯åä¼šè‡ªåŠ¨åœ¨åå°å‹ç¼©å†å²\n")

        while True:
            self.chat()


if __name__ == "__main__":
    ai_system = AiSystem()
    ai_system.main()